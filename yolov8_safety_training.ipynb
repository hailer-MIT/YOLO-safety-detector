{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# YOLOv8 Fine-Tuning for Safety Detection (Hard Hats & Vests)\n",
                "\n",
                "This notebook demonstrates how to fine-tune a YOLOv8 model to detect safety equipment using the Hard Hat Workers dataset from Roboflow.\n",
                "\n",
                "## Step 1: Install Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install ultralytics roboflow"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Download the Dataset\n",
                "\n",
                "### ðŸ”‘ How to find your Roboflow API Key:\n",
                "1. Log in to [Roboflow](https://app.roboflow.com/)\n",
                "2. Click your **Profile Picture** (top right) > **Settings**\n",
                "3. On the left sidebar, select **Workspaces**\n",
                "4. Select your workspace and click **Roboflow API**\n",
                "5. Copy your **Private API Key** and paste it below."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from roboflow import Roboflow\n",
                "rf = Roboflow(api_key=\"YOUR_PRIVATE_API_KEY\")\n",
                "project = rf.workspace(\"pedro-olivares-1lezt\").project(\"hard-hat-workers-dataset\")\n",
                "version = project.version(1)\n",
                "dataset = version.download(\"yolov8\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3: Train the Model\n",
                "\n",
                "We use the `yolov8n.pt` (nano) model as a base for transfer learning."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from ultralytics import YOLO\n",
                "\n",
                "# Load a pretrained YOLOv8n model\n",
                "model = YOLO('yolov8n.pt')\n",
                "\n",
                "# Train the model\n",
                "results = model.train(\n",
                "    data=f\"{dataset.location}/data.yaml\",\n",
                "    epochs=50,\n",
                "    imgsz=640,\n",
                "    plots=True\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 4: Validate and Evaluate\n",
                "\n",
                "Check the mAP50 and other metrics."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "metrics = model.val()\n",
                "print(f\"mAP50: {metrics.box.map50}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 5: Run Inference on a Sample Image"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import cv2\n",
                "import os\n",
                "from google.colab.patches import cv2_imshow\n",
                "\n",
                "# Run prediction on an image from the test set\n",
                "test_images_path = os.path.join(dataset.location, 'test', 'images')\n",
                "test_images = os.listdir(test_images_path)\n",
                "img_path = os.path.join(test_images_path, test_images[0])\n",
                "\n",
                "results = model.predict(source=img_path, save=True)\n",
                "res_img = results[0].plot()\n",
                "cv2_imshow(res_img)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 6: Export the Model\n",
                "\n",
                "Export to ONNX format or just keep the `best.pt` for deployment."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.export(format='onnx') # Optional: Export for other platforms"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}